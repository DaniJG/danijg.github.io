{"componentChunkName":"component---node-modules-gatsby-theme-chronoblog-src-templates-post-js","path":"/its-always-dns/","result":{"data":{"mdx":{"id":"defff24a-0328-56cc-b5df-510d8a3b97bb","excerpt":"I frequently interact with several Kubernetes clusters which sit behind a corporate VPN. The fact that one has to be connected to the VPN inâ€¦","frontmatter":{"title":"It is always DNS. A kubectl story","date":"2020-10-15T00:00:00.000Z","description":"Why kubectl stopped being able to interact with private clusters located behind a VPN","tags":["post","kubernetes"],"cover":null},"fields":{"slug":"/its-always-dns/"},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"It is always DNS. A kubectl story\",\n  \"date\": \"2020-10-15T00:00:00.000Z\",\n  \"description\": \"Why kubectl stopped being able to interact with private clusters located behind a VPN\",\n  \"tags\": [\"post\", \"kubernetes\"]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"I frequently interact with several Kubernetes clusters which sit behind a corporate VPN. The fact that one has to be connected to the VPN in order to access these clusters had never granted a second thought.\"), mdx(\"p\", null, \"Long time ago I installed \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" in my laptop using Homebrew (see \", mdx(\"a\", _extends({\n    parentName: \"p\"\n  }, {\n    \"href\": \"https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-with-homebrew-on-macos\"\n  }), \"instructions here\"), \"). Since then, I kept using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" to connect to those clusters without problems, as long as I was also connected to the VPN.\"), mdx(\"p\", null, \"One day, I started noticing the following error message:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"$ kubectl get pod\\nUnable to connect to the server: dial tcp: lookup my-cluster.contoso.io on 192.168.0.1:53: no such host\\n\")), mdx(\"h2\", {\n    \"id\": \"troubleshooting-and-fixing-the-issue\"\n  }, \"Troubleshooting and fixing the issue\"), mdx(\"p\", null, \"This was very puzzling. I had been using \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" with no problem until very recently. Even more confusing was the result of my immediate troubleshooting:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"I was definitely connected to the VPN\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"I could resolve \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"my-cluster.contoso.io\"), \" when using other tools like \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"curl\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"ping\"), \", or \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"dig +trace\"))), mdx(\"p\", null, \"What was going on? I checked with my colleagues in case they were experiencing the same issue. Of course, they weren't! The next immediate action was to compare the versions of kubectl we were using.\"), mdx(\"p\", null, \"When we compared versions, I was several versions behind theirs. With nothing better to try out, I decided to upgrade kubectl as in\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"brew upgrade kubernetes-cli\\n\")), mdx(\"p\", null, \"And this is where I grabbed the thread to find out what was going on! When Homebrew upgraded \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \", it finished by complaining that \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"/usr/bin/local/kubectl\"), \" had been symlinked to a different location than the previous Homebrew installation. Even more interesting was the fact that the current binary pointed to my Docker for Mac installation!\"), mdx(\"p\", null, \"I tried the suggested fix to repoint the binary:\"), mdx(\"pre\", null, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"brew link --overwrite  kubernetes-cli\\n\")), mdx(\"p\", null, \"And just like that, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" started working again \\uD83D\\uDE80\"), mdx(\"h2\", {\n    \"id\": \"the-root-cause\"\n  }, \"The root cause\"), mdx(\"p\", null, \"I wasn't happy though. Since I didnt know why this happened, I was concerned it could happen again. Googling on the basis Docker for mac is doing something funny to my kubectl. Shortly after I found that indeed Docker for mac will repoint your \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" when installed \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"or upgraded\"), \".\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Note the issue was closed due to \", mdx(\"em\", {\n    parentName: \"li\"\n  }, \"inactivity\"), \": \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/docker/for-mac/issues/2368\"\n  }), \"https://github.com/docker/for-mac/issues/2368\"))), mdx(\"p\", null, \"That explained why the binary installed by Homebrew was repointed by Docker. However, why was the Docker version unable to reach out to clusters behind the VPN? What's so different between the 2 versions?\"), mdx(\"p\", null, \"As it turns out, \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" inherits an issue fro Go, whereby DNS resolution would only pick whatever is found in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"/etc/resolv.conf\"), \" rather than using the MacOS stack for DNS resolution.\\nThe way to prevent the issue is by compiling your Go application with the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"CGO_ENABLED=1\"), \" environment variable.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"See the open issue: \", mdx(\"a\", _extends({\n    parentName: \"li\"\n  }, {\n    \"href\": \"https://github.com/kubernetes/kubernetes/issues/23130#issuecomment-572292652\"\n  }), \"https://github.com/kubernetes/kubernetes/issues/23130#issuecomment-572292652\"))), mdx(\"p\", null, \"As you can read in that issue's thread, the Homebrew distribution of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" does indeed compile it with \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"CGO_ENABLED=1\"), \" while the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"official\"), \" google release doesn't.\"), mdx(\"p\", null, \"That solves the mystery. Upgrading docker caused the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" binary to be repointed to a version of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" redistributed by Docker. While the Homebrew version is compiled to correctly resolve DNS in MacOS, Docker is redistributing the \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"official\"), \" google release which isnt compiled this way!\"), mdx(\"h2\", {\n    \"id\": \"tldr\"\n  }, \"TL;DR\"), mdx(\"p\", null, \"If you are a Mac user:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Always install kubectl in Mac using Homebrew\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"If you notice DNS resolution errors connecting to clusters behind a VPN, its likely Docker for Mac repointed the \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"kubectl\"), \" binary to its own version. Restore to the Homebrew version with:\", mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", _extends({\n    parentName: \"pre\"\n  }, {}), \"brew link --overwrite  kubernetes-cli\\n\")))), mdx(\"p\", null, \"For everyone else, remember \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"it's always DNS!\")));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"id":"defff24a-0328-56cc-b5df-510d8a3b97bb"}},"staticQueryHashes":["1961101537","2542493696"]}